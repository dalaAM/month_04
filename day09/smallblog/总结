淘汰策略(redis中key的删除规则)
​	1.主动出击
​		把所有带过期时间的key另外的存储到一个字典当中,定期扫描,判断key是否过期,
        默认每100毫秒进行一次过期扫描
        1>在过期字典中随机的选择20个key
        2>检查过期的key,删除已经到期的
        3>如果过期的key比例超过1/4,重复执行1~3步骤
        默认的超过时间是25秒,避免扫描卡死.
   2.惰性删除 get key,如果该key已经过期,则删除
   3.redis检查内存的使用超过maxmemory,开始暴力淘汰策略
    3.1 noeviction-拒绝写服务,可以接收读的请求.[默认值]
    3.2 volatile-lru-尝试删除带过期时间但是很少使用的key
    3.3 allkeys-lru -尝试删除所有很少使用的key[最少使用原则]
        如何判断key值使用次数最少?
            假设一个队列中是三个key,在每次使用key的时候就将使用的key放到队列的最上边,当长时间不使用某一个key时,
            就将这个key放到队列最低处


位图操作:
    可以进行实时的统计用户的登录信息? (如:那些用户那几天登录过?),且及其节省内存空间
    如不引入位图操作:(统计用户信息)
        1_login:[20200518,20200615]
        2_login:[20200614,20200323]
        如果一个用户一年都在登录,则key值有365个
        在有许多用户的前提下一年都在登录,则会耗费大量的内存空间
    引入位图操作:(设1年中的第一天为0位,最后一天为364位,'1'和'0'表示登录或者没有登录)
        1_login:01000100011011
        2_login:01000100011011
        这样操作则会俭省大量的内存空间
        操作时统计字节的整数倍
    使用场景:
        用户登录信息统计,活跃度统计
        a:0110 0001
        b:0110 0010
        q:0111 0001
        r:0111 0010

Hash散列数据类型
    1、由field和关联的value组成的键值对
    2、field和value是字符串类型
    3、一个hash中最多包含2^32-1个键值对
    key:str
    key:[v1,v2,v3] 列表
    key:{f1:v1,f2:v2,f3:v3} 字典
    使用hash散列操作
        优点:节约内存空间,字段不能超过512个,value超过64个字节
            可按需获取字段的值,(file与file之间相互独立,不需要索引,f1和f2同属于一个key)
        缺点:
            使用过期键功能:键过期功能只能对键进行过期操作,而不能对散列的字段进行过期操作
    在redis中但凡字典操作命令都已'H'操作,列表操作命令都已'L'操作,集合操作命令都已'S'操作,有序集合操作命令都已'Z'操作


model:
class user:
    username
    age
    1.获取用户信息:
    url:user/detail/1
    views中的相关使用函数
    if 缓存中有数据 redis
        return 缓存中的数据

    else:
        从数据库当中查询 -->mysql
        将数据存到缓存 -->redis (如何存?)
        return 数据

    2.更新用户信息:
    url:user/update/<int:user_id>
    更新前需要设置post提交(需要添加模板)
        user/update/1?age =30
    view中添加相关函数
        1查 2改 3保存
        删除redis中的缓存


有序集合sortedset (一般用于排行榜)
    1.有序,去重
    2.在有序集合当中没有差集,只有交集和并集
    3.在交集当中,可以求两个集合生成交集的最大值和最小值,并且求和,同时可以根据权重求和


python 字典的原理(redis中的hash)
d ={} 当定义一个空字典时,内存会开辟一个长度为8的内存空间,相当于初始化一个长度为8的数组
2.d['a']=123,-->hash('a')%8  一定会在数组当中,假设其结果是'7'
当添加元素时,相当于对键求一个hash值,如果hash值特别长,那么会对hash值求余那么值一定在8以内
3,d['z']=456,-->hash('z')%8,
数据量越大,利用哈希运算查找数据越快
    当发生hash碰撞时:(两个值的哈希运算的结果(地址)一致)
        redis:还在原来的位置,对应位置上创建一个单向列表 (单链法) 每个位置上最多不超过4个元素
        python:使用开放地址法 hash(7+偏移量)=new位置,new位置有元素,再计算,直到有空位置为止
                如果使用的位置超过2/3,马上扩容.
                长度5w以下扩容4倍.5w以上扩容2倍,扩容之后每一个元素位置需要重新做哈希运算.
                因此字典的值是没有固定的元素的







redis 由于redis是内存数据库,主要目的是在高并发的状态下支持快速响应,
回滚是事物的代码执行时失败重新执行事物,从而造成不能快速响应,与redis设计初衷不符.


pipeline 流水线
    事物来了不先提交,先在客户端放在队列当中,一次性提交给服务器,降低网络io的操作,提升效率.

池化技术思想:
    线程池:一般线程操作在一个线程在使用完之后需要销毁,在高并发的状态下,如果使用一般线程操作需要频繁的创建线程和销毁线程,
    从而大量的消耗cpu的资源,而线程池是在线程使用完之后,不销毁,等待下一次使用.从而避免了cpu大量消耗.
    连接池:一般在连接数据库是也是需要的建立连接和关闭连接,如果在高并发的状态下,频繁的建立连接和关闭连接,响应速度会变慢,
    连接池在使用完之后不关闭连接,等待下一个事物使用,


乐观锁:
    乐观的认为在我事物执行过程中,别人不会修改某个key的值,但是如果被修改了,但是如果被修改了,我的这次事物就不执行了.
    不改就用,修改就不用.
    事物过程中,可对指定key进行监听,命令提交时,若被监听key对应的值未被修改时,事物方可提交成功,否则失败















